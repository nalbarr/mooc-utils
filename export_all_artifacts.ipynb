{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export_all_artifacts\n",
    "\n",
    "This is a utility notebook to download MOOC artifacts for local development and analysis\n",
    "- NOTE: This will not work if a course module artifact total compressed tar and gzip (i.e., .tgz) exceeds 100 MB.  In this case use export_split.sh and import_merge.sh scripts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import glob, zipfile, os, os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32\r\n",
      "0 drwxr-xr-x    8 nalbarr  staff   256 May 16 16:05 \u001b[34m.\u001b[m\u001b[m\r\n",
      "0 drwxr-xr-x+ 193 nalbarr  staff  6176 May 16 15:50 \u001b[34m..\u001b[m\u001b[m\r\n",
      "0 drwxr-xr-x   12 nalbarr  staff   384 May 16 15:50 \u001b[34m.git\u001b[m\u001b[m\r\n",
      "8 -rw-r--r--    1 nalbarr  staff  1799 May 16 15:50 .gitignore\r\n",
      "0 drwxr-xr-x    3 nalbarr  staff    96 May 16 15:59 \u001b[34m.ipynb_checkpoints\u001b[m\u001b[m\r\n",
      "8 -rw-r--r--    1 nalbarr  staff  1075 May 16 15:50 LICENSE\r\n",
      "8 -rw-r--r--    1 nalbarr  staff    24 May 16 15:50 README.md\r\n",
      "8 -rw-r--r--    1 nalbarr  staff  3999 May 16 16:05 export_artifacts.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "# explore course module directory and artifacts\n",
    "!ls -las"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually update file paths\n",
    "\n",
    "After inspecting course directory structure.  Update get_filepaths() function to ensure you are downloading what artifacts you are interested in.\n",
    "\n",
    "### Examples:\n",
    "- Notebook files as *.ipynb\n",
    "- Python utility files as *.py\n",
    "- Images\n",
    "- Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepaths():\n",
    "    notebooks_path = os.path.join('.', \"*.ipynb\")\n",
    "    notebooks = glob.glob(notebooks_path)\n",
    "    \n",
    "    sources_path = os.path.join('.', '*.py')\n",
    "    sources = glob.glob(sources_path)\n",
    "    \n",
    "    # NAA.  No datasets.\n",
    "    #datasets_path = os.path.join()\n",
    "    #datasets = glob.glob(datasets_path)\n",
    "    datasets = []\n",
    "    \n",
    "    images_path = os.path.join('.', 'images', '*.*')\n",
    "    images = glob.glob(images_path)\n",
    "\n",
    "    #print (type(datasets))\n",
    "    #print(\"datasets: \" + str(datasets))\n",
    "    #print(\"images: \" + str(images))\n",
    "\n",
    "    filepaths = notebooks + sources + datasets + images\n",
    "    if (debug):\n",
    "        print(\"filepaths: \" + str(filepaths))\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_files(zipfilename):\n",
    "    filepaths = get_filepaths()\n",
    "    \n",
    "    if (debug):\n",
    "        with zipfile.ZipFile(zipfilename, 'w') as myzip:\n",
    "            for f in filepaths:\n",
    "                print(\"f: \" + f)\n",
    "                myzip.write(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_export_file(zipfilename):\n",
    "    if (os.path.isfile(zipfilename)):\n",
    "        print(\"Export successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set module name here\n",
    "- You may want to match your Github repository naming.\n",
    "  - e.g., deeplearning.ai-course1-week3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set module name here !\n",
    "# You may want to match your Github repository naming.\n",
    "# e.g., deeplearning.ai-course1-week3\n",
    "module_name=\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run exporter\n",
    "- Run exporter\n",
    "- (Optional) Turn on debug flag to see more details\n",
    "- Inspect files exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepaths: ['./export_course1_week3.py.ipynb', './Planar data classification with one hidden layer v4.ipynb', './planar_utils.py', './testCases_v2.py', './images/sgd_bad.gif', './images/classification_kiank.png', './images/sgd.gif', './images/grad_summary.png']\n",
      "f: ./export_course1_week3.py.ipynb\n",
      "f: ./Planar data classification with one hidden layer v4.ipynb\n",
      "f: ./planar_utils.py\n",
      "f: ./testCases_v2.py\n",
      "f: ./images/sgd_bad.gif\n",
      "f: ./images/classification_kiank.png\n",
      "f: ./images/sgd.gif\n",
      "f: ./images/grad_summary.png\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "\n",
    "zipfilename = \"{}.zip\".format(module_name)\n",
    "zipfilepath = os.path.join(\".\", zipfilename)\n",
    "debug=True\n",
    "export_files(zipfilepath)\n",
    "check_export_file(zipfilepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
